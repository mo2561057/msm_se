{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from scipy import stats\n",
    "\n",
    "import estimagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordered Logit Example\n",
    "We use a multidimensional least squares problem.\n",
    "The outcome depends on a number of fixed observables.\n",
    "We however only have conditional moments instead of individual level outcomes.\n",
    "This is a very stylized example since the estimation problem is not really different and because we have moments for each set of \n",
    "observabes. In general such problems will involve endogenous and dynamic choices. To example is however sufficient to show the basic \n",
    "mechanics of standart error calculation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_processing(formula, data):\n",
    "    \"\"\"Process user input for an ordered logit model.\"\"\"\n",
    "    # extract data arrays\n",
    "    y, x = dmatrices(formula + \" - 1\", data, return_type=\"dataframe\")\n",
    "    y = y[y.columns[0]]\n",
    "\n",
    "    # extract dimensions\n",
    "    num_choices = len(y.unique())\n",
    "    beta_names = list(x.columns)\n",
    "    num_betas = len(beta_names)\n",
    "    num_cutoffs = num_choices - 1\n",
    "\n",
    "    # set-up index for params_df\n",
    "    names = beta_names + list(range(num_cutoffs))\n",
    "    categories = [\"beta\"] * num_betas + [\"cutoff\"] * num_cutoffs\n",
    "    index = pd.MultiIndex.from_tuples(zip(categories, names), names=[\"type\", \"name\"])\n",
    "\n",
    "    # make params_df\n",
    "    np.random.seed(5471)\n",
    "    start_params = pd.DataFrame(index=index)\n",
    "    start_params[\"value\"] = np.hstack(\n",
    "        [\n",
    "            np.random.uniform(low=-0.5, high=0.5, size=len(x.columns)),\n",
    "            np.arange(num_cutoffs) * 2,\n",
    "        ]\n",
    "    )\n",
    "    start_params[\"group\"] = start_params.index.get_level_values(\"type\")\n",
    "\n",
    "    # make constraints\n",
    "    constr = [{\"loc\": \"cutoff\", \"type\": \"increasing\"}]\n",
    "\n",
    "    # turn pandas objects into numpy arrays\n",
    "    y_arr = y.to_numpy().astype(int)\n",
    "    x_arr = x.to_numpy()\n",
    "\n",
    "    return start_params, y_arr, x_arr, constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_moments(x,y):\n",
    "    im = pd.DataFrame(data=x.copy(),columns=[\"pared\",\"public\",\"gpa\"])\n",
    "    im[\"apply\"] = y\n",
    "    im[\"gpa\"] = pd.cut(im.gpa,bins=5,labels=False)\n",
    "    ix = pd.MultiIndex.from_tuples(itertools.product(range(2),range(2),range(5),range(3)))\n",
    "    ix.names = [\"pared\", \"public\",\"gpa\", \"apply\"]\n",
    "    out = pd.Series(index=ix,data=0)\n",
    "    rslt =  im.groupby([\"pared\",\"public\",\"gpa\"])[\"apply\"].value_counts(normalize=True)\n",
    "    out[rslt.index] = rslt.values\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_msm(\n",
    "    params,\n",
    "    x,\n",
    "    moment_func,\n",
    "    moments_obs,\n",
    "    weighting=[]\n",
    "):\n",
    "    \"\"\"MSM criterion for ordered logit\"\"\"\n",
    "    # parse the parameter vector into its quantities\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "\n",
    "    # calculate deterministic part of utilities\n",
    "    xb = x.dot(beta).reshape(len(x),1)\n",
    "\n",
    "    # Simulate Result:\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "\n",
    "    prob_cumulative = (upper_cdf - lower_cdf).cumsum(axis=1)\n",
    "    draws = np.random.rand(len(xb), 1)\n",
    "    labels = (draws < prob_cumulative).argmax(axis=1)\n",
    "    \n",
    "    moments_sim = moment_func(x, labels)\n",
    "    \n",
    "    dev = (moments_sim - moments_obs).values\n",
    "    \n",
    "    if len(weighting)==0:\n",
    "        weighting = np.identity(len(moments_obs))\n",
    "        \n",
    "    return dev @ weighting @ dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set\n",
    "data = pd.read_pickle(\"~/OpenSourceEconomics/estimagic/docs/source/getting_started/ologit.pickle\")\n",
    "formula = \"apply ~ pared + public + gpa\"\n",
    "start_params, y, x, constraints = ordered_logit_processing(formula, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we are not allowed to keep the dependent information due to privacy concerns.\n",
    "We are only allowed to extract a moments at a certain level of granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments_obs = _build_moments(x,y)\n",
    "# Now we pretend to leave our secure work space. Thus we have to delete y.\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need a weighting matrix. We start with the identity\n",
    "weighting = np.identity(len(moments_obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the objective function\n",
    "objective = functools.partial(\n",
    "    ordered_logit_msm,\n",
    "    x=x,\n",
    "    moment_func=_build_moments,\n",
    "    moments_obs=moments_obs,\n",
    "    weighting=weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.292995381283753"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We perform one evaluation to make sure our setup works\n",
    "objective(start_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generic_standart_errors(objective, theta_hat, covariance_matrix):\n",
    "    # Get Hessian Matrix\n",
    "    H = None\n",
    "    \n",
    "    # Think about correct scaling\n",
    "    \n",
    "    # Build Wraper\n",
    "    return np.sqrt(1/H.shape[0]) * (H @ covariance_matrix @ H)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
