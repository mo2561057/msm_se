{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from scipy import stats\n",
    "from estimagic import minimize, maximize\n",
    "from estimagic.differentiation.derivatives import first_derivative\n",
    "from respy.method_of_simulated_moments import _harmonize_input, get_flat_moments\n",
    "import estimagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimagic.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Standart Errors MSM \n",
    "## Ordered Logit Example\n",
    "This notebook contains a full tutorial about standart errors with method of simuated moments.\n",
    "We continue the maximum likelihood example and still consider an ordered logit case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset(n_agents, params):\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "    range_vars = np.random.choice(range(2,7),size=len(beta))\n",
    "    X = np.concatenate([np.random.choice(range(x),size=n_agents).reshape(n_agents,1) for x in range_vars],axis=1)\n",
    "\n",
    "    # calculate deterministic part of utilities\n",
    "    xb = X.dot(beta).reshape(n_agents,1)\n",
    "\n",
    "    # Simulate Result:\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "\n",
    "    prob_cumulative = (upper_cdf - lower_cdf).cumsum(axis=1)\n",
    "    draws = np.random.rand(len(xb), 1)\n",
    "    labels = (draws < prob_cumulative).argmax(axis=1)\n",
    "    out = pd.DataFrame(X)\n",
    "    out.columns = params.loc[\"beta\"].index.values\n",
    "    out[\"y\"] = labels\n",
    "    return out\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_data_df(x,y,cols):\n",
    "    # Basic utility\n",
    "    data = np.concatenate([x,y.reshape(len(y),1)],axis=1)\n",
    "    return pd.DataFrame(data=data.copy(),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_processing(formula, data):\n",
    "    \"\"\"Process user input for an ordered logit model.\"\"\"\n",
    "    # extract data arrays\n",
    "    y, x = dmatrices(formula + \" - 1\", data, return_type=\"dataframe\")\n",
    "    y = y[y.columns[0]]\n",
    "\n",
    "    # extract dimensions\n",
    "    num_choices = len(y.unique())\n",
    "    beta_names = list(x.columns)\n",
    "    num_betas = len(beta_names)\n",
    "    num_cutoffs = num_choices - 1\n",
    "\n",
    "    # set-up index for params_df\n",
    "    names = beta_names + list(range(num_cutoffs))\n",
    "    categories = [\"beta\"] * num_betas + [\"cutoff\"] * num_cutoffs\n",
    "    index = pd.MultiIndex.from_tuples(zip(categories, names), names=[\"type\", \"name\"])\n",
    "\n",
    "    # make params_df\n",
    "    np.random.seed(5471)\n",
    "    start_params = pd.DataFrame(index=index)\n",
    "    start_params[\"value\"] = np.hstack(\n",
    "        [\n",
    "            np.random.uniform(low=-0.5, high=0.5, size=len(x.columns)),\n",
    "            np.arange(num_cutoffs) * 2,\n",
    "        ]\n",
    "    )\n",
    "    start_params[\"group\"] = start_params.index.get_level_values(\"type\")\n",
    "\n",
    "    # make constraints\n",
    "    constr = [{\"loc\": \"cutoff\", \"type\": \"increasing\"}]\n",
    "\n",
    "    # turn pandas objects into numpy arrays\n",
    "    y_arr = y.to_numpy().astype(int)\n",
    "    x_arr = x.to_numpy()\n",
    "    \n",
    "    return start_params, y_arr, x_arr, constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_moments(data, ind):\n",
    "    im = data.copy()\n",
    "    #im[\"gpa\"] = pd.qcut(im.gpa,q=3,labels=False)\n",
    "    ranges = data.max(axis=0)\n",
    "    ix = pd.MultiIndex.from_tuples(itertools.product(*(range(int(x + 1)) for x in ranges)))\n",
    "    ix.names = ind + [\"y\"]\n",
    "    out = pd.Series(index=ix,data=0)\n",
    "    rslt =  im.groupby(ind)[\"y\"].value_counts(normalize=True)\n",
    "    out[rslt.index] = rslt.values\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighting_matrix(\n",
    "    data,\n",
    "    empirical_moments,\n",
    "    calc_moments,\n",
    "    n_bootstrap_samples,\n",
    "    n_draws_individuals,\n",
    "    replace_missing_weights=None,\n",
    "    return_covariance_matrix=False,\n",
    "):\n",
    "    \"\"\"Compute a diagonal weighting matrix for estimation with MSM.\n",
    "    Weights are the inverse bootstrap variances of the observed sample moments.\n",
    "    Args:\n",
    "    ------\n",
    "    data (pandas.DataFrame)\n",
    "        Dataframe containing individual observations. Must contain index named\n",
    "        \"Identifier\" by which observations are sampled.\n",
    "    empirical_moments (dict)\n",
    "        Dictionary containing empirical moments in the form of pandas.DataFrame\n",
    "        or pandas.Series.\n",
    "    calc_moments (dict)\n",
    "        Dictionary containing moment functions.\n",
    "    n_bootstrap_samples (int)\n",
    "        Number of samples that should be boostrapped.\n",
    "    n_draws_individuals (int)\n",
    "        Observations per bootstrap sample (individual ids).\n",
    "    replace_missing_weights (None or float)\n",
    "        Can be used to replace missing weights with a float value. If none, in\n",
    "        cases where where weights are computed to be missing/infinite (i.e. if\n",
    "        variances are 0), weights are set to zero.\n",
    "    return_covariance_matrix : bool, default False\n",
    "        Return full covariance matrix of bootstrapped moments.\n",
    "    Returns:\n",
    "    --------\n",
    "    weighting_matrix (numpy.array)\n",
    "        Diagonal weighting matrix with dimensions RxR where R denotes the\n",
    "        number of moments.\n",
    "    covariance_matrix (numpy.array)\n",
    "        Covariance matrix of moments.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    np.random.seed(123)\n",
    "    flat_empirical_moments = get_flat_moments(empirical_moments)\n",
    "    index_base = data.index.get_level_values(0).unique()\n",
    "    calc_moments = _harmonize_input(calc_moments)\n",
    "    # Create bootstrapped moments.\n",
    "    moments_sample = []\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        ids_boot = np.random.choice(index_base, n_draws_individuals, replace=False)\n",
    "        moments_boot = {k: func(data.loc[ids_boot]) for k, func in calc_moments.items()}\n",
    "        flat_moments_boot = get_flat_moments(moments_boot)\n",
    "        flat_moments_boot = flat_moments_boot.reindex_like(flat_empirical_moments)\n",
    "        # flat_moments_boot = flat_moments_boot.fillna(0)\n",
    "        moments_sample.append(flat_moments_boot)\n",
    "\n",
    "    # Compute variance for each moment and construct diagonal weighting matrix.\n",
    "    moments_var = np.array(moments_sample).var(axis=0)\n",
    "\n",
    "    # The variance of missing moments is nan. Unless a replacement variance is\n",
    "    # specified, their inverse variance will be set to 0.\n",
    "    diagonal = moments_var ** (-1)\n",
    "    if replace_missing_weights is None:\n",
    "        diagonal = np.nan_to_num(diagonal, nan=0, posinf=0, neginf=0)\n",
    "    else:\n",
    "        diagonal = np.nan_to_num(\n",
    "            moments_var,\n",
    "            nan=replace_missing_weights,\n",
    "            posinf=replace_missing_weights,\n",
    "            neginf=replace_missing_weights,\n",
    "        )\n",
    "\n",
    "    weighting_matrix = np.diag(diagonal)\n",
    "\n",
    "    # Checks weighting matrix.\n",
    "    if np.isnan(weighting_matrix).any() or np.isinf(weighting_matrix).any():\n",
    "        raise ValueError(\"Weighting matrix contains NaNs or infinite values.\")\n",
    "\n",
    "    if return_covariance_matrix:\n",
    "        covariance_matrix = np.cov(np.array(moments_sample).T, ddof=0)\n",
    "        out = weighting_matrix, covariance_matrix\n",
    "        assert np.allclose(\n",
    "            moments_var, np.diag(covariance_matrix)\n",
    "        ), \"Variances in two outputs are not equal.\"\n",
    "    else:\n",
    "        out = weighting_matrix\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_msm(\n",
    "    params,\n",
    "    x,\n",
    "    moment_func,\n",
    "    moments_obs,\n",
    "    cols,\n",
    "    weighting=[],\n",
    "    return_scalar=True\n",
    "    \n",
    "):\n",
    "    \"\"\"MSM criterion for ordered logit\"\"\"\n",
    "    # parse the parameter vector into its quantities\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "\n",
    "    # calculate deterministic part of utilities\n",
    "    xb = x.dot(beta).reshape(len(x),1)\n",
    "\n",
    "    # Simulate Result:\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "\n",
    "    prob_cumulative = (upper_cdf - lower_cdf).cumsum(axis=1)\n",
    "    draws = np.random.rand(len(xb), 1)\n",
    "    labels = (draws < prob_cumulative).argmax(axis=1)\n",
    "    \n",
    "    moments_sim = moment_func(_build_data_df(x,labels,cols))\n",
    "    \n",
    "    dev = (moments_sim - moments_obs).values\n",
    "    \n",
    "    if len(weighting)==0:\n",
    "        weighting = np.identity(len(moments_obs))\n",
    "    \n",
    "    if return_scalar:\n",
    "        return dev @ weighting @ dev\n",
    "    else:\n",
    "        return dev @ np.sqrt(weighting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.DataFrame(pd.Series({\n",
    "    (\"beta\",\"a\"):-2,\n",
    "    (\"beta\",\"b\"):1,\n",
    "    (\"beta\",\"c\"):3,\n",
    "    (\"cutoff\",0):2,\n",
    "    (\"cutoff\",1):4,\n",
    "}))\n",
    "params.columns = [\"value\"]\n",
    "params[\"lower_bound\"] = - np.inf\n",
    "params[\"upper_bound\"] = np.inf\n",
    "\n",
    "params.index = pd.MultiIndex.from_tuples(params.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">beta</th>\n",
       "      <th>a</th>\n",
       "      <td>-2</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cutoff</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          value  lower_bound  upper_bound\n",
       "beta   a     -2         -inf          inf\n",
       "       b      1         -inf          inf\n",
       "       c      3         -inf          inf\n",
       "cutoff 0      2         -inf          inf\n",
       "       1      4         -inf          inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = simulate_dataset(10000, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a  b  c  y\n",
       "0     1  1  0  0\n",
       "1     0  1  1  2\n",
       "2     0  1  1  0\n",
       "3     1  1  0  0\n",
       "4     0  0  0  0\n",
       "...  .. .. .. ..\n",
       "9995  1  0  1  0\n",
       "9996  0  1  0  0\n",
       "9997  2  1  1  0\n",
       "9998  2  1  0  0\n",
       "9999  2  0  0  0\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set\n",
    "#data = pd.read_pickle(\"~/OpenSourceEconomics/estimagic/docs/source/getting_started/ologit.pickle\")\n",
    "formula = \"y ~ a + b + c\"\n",
    "start_params, y, x, constraints = ordered_logit_processing(formula, data)\n",
    "n = x.shape[0]\n",
    "n_agents_sim = 10000\n",
    "cols = [\"a\",\"b\",\"c\",\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_params.loc[\"beta\"].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we are not allowed to keep the dependent information due to privacy concerns.\n",
    "We are only allowed to extract a moments at a certain level of granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = _build_data_df(x, y)\n",
    "ind = list(start_params.loc[\"beta\"].index.values)\n",
    "moments_obs = _build_moments(data,ind)\n",
    "moment_func = functools.partial(_build_moments,ind=ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mo2561057/anaconda3/envs/ov_analysis/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in reciprocal\n"
     ]
    }
   ],
   "source": [
    "weighting, S = get_weighting_matrix(\n",
    "    data,\n",
    "    moments_obs,\n",
    "    moment_func,\n",
    "    n_bootstrap_samples=500,\n",
    "    n_draws_individuals=100,\n",
    "    replace_missing_weights=None,\n",
    "    return_covariance_matrix=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we pretend to leave our secure work space. Thus we have to delete y.\n",
    "del y\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the objective function\n",
    "objective = functools.partial(\n",
    "    ordered_logit_msm,\n",
    "    x=x,\n",
    "    moment_func=moment_func,\n",
    "    moments_obs=moments_obs,\n",
    "    weighting=weighting,\n",
    "    cols=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.],\n",
       "       [0., 1., 1.],\n",
       "       [0., 1., 1.],\n",
       "       ...,\n",
       "       [2., 1., 1.],\n",
       "       [2., 1., 0.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform one evaluation to make sure our setup works\n",
    "objective(start_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optmize\n",
    "rslt = minimize(\n",
    "    criterion=objective,\n",
    "    params=start_params,\n",
    "    algorithm=\"scipy_powell\",\n",
    "    constraints=constraints,\n",
    "    logging=\"ordered_logit.db\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rslt[\"solution_params\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sandwich_cov(G, W, S, n):\n",
    "    bread = np.linalg.inv(\n",
    "        G.T @ W @ G\n",
    "    )\n",
    "    butter = G.T @ W @ S @ W @ G\n",
    "    return bread @ butter @ bread / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msm_standart_errors(objective, theta_hat, S, W, n):\n",
    "    # Get Hessian Matrix\n",
    "    G = first_derivative(\n",
    "    objective, \n",
    "    theta_hat, \n",
    "    method=\"central\", \n",
    "    #key=\"moment_errors\", \n",
    "    base_steps=0.3,\n",
    "    return_func_value=True,\n",
    "    n_cores=1,\n",
    "    )[0].to_numpy()\n",
    "    \n",
    "    \n",
    "    return sandwich_cov(G, W, S, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = functools.partial(\n",
    "    ordered_logit_msm,\n",
    "    x=x,\n",
    "    moment_func=moment_func,\n",
    "    moments_obs=moments_obs,\n",
    "    weighting=weighting,\n",
    "    return_scalar=False,\n",
    "    cols=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = objective(start_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = get_msm_standart_errors(objective, params, S, weighting , n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34740956e-04, 6.37699663e-05, 7.90890875e-05, 1.11444044e-04,\n",
       "       1.13477077e-04])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.diag(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
