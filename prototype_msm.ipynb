{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from scipy import stats\n",
    "from estimagic import minimize, maximize\n",
    "from estimagic.differentiation.derivatives import first_derivative\n",
    "from respy.method_of_simulated_moments import _harmonize_input, get_flat_moments\n",
    "import estimagic\n",
    "from estimagic import maximize\n",
    "from estimagic.inference.likelihood_inference import do_likelihood_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimagic.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Standart Errors MSM \n",
    "## Ordered Logit Example\n",
    "This notebook contains a full tutorial about standart errors with method of simuated moments.\n",
    "We continue the maximum likelihood example and still consider an ordered logit case.\n",
    "- I particular we simulate a dataset with a data generating process given by a simple ordered logit model.\n",
    "\n",
    "- We simulate data and only use discrete values of the independent variable because it makes the method of moments example more explicit.\n",
    "\n",
    "- We take the simulated dataset and build conditional moments of the outcome variable for each combination of independent variables.\n",
    "\n",
    "- Since these variables are discrete there is a finite number of such moments and  we do not need to discretize any data.\n",
    "\n",
    "- Thereafter we discard the observed dependent variable and only keep the \"observed\" moments and observed independent variables.\n",
    "\n",
    "- The objective function takes an arbitrary parameter vector and the observed \n",
    "  independent variables and maps them into implied population moments.\n",
    "  Particularly it uses these inputs and generates outcomes for each individual   with the ordered logit model.\n",
    "\n",
    "- Then it builds simulated moments with these outcomes and compares them to the  observed moments.\n",
    "\n",
    "- The opimization procedure choses the parameter vector that minimizes the distance between observed and simulated moments.\n",
    "\n",
    "- Then we build standart errors. Importantly we get weighting matrix and the asymptotic variance matrix with a bootstrap procedure.\n",
    "\n",
    "- Sources for standart errors:\n",
    "https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA7560\n",
    "https://eml.berkeley.edu/choice2/ch10.pdf\n",
    "(Please add any references)\n",
    "\n",
    "- Altough this is not strictly necessary in our case it is generally required in  any example that uses higher order moments in the data.\n",
    "\n",
    "- Thereafter it is important to correct for the amount of bootstrap samples.\n",
    "\n",
    "- We compare standart errors to maximum likelihood and find that they are approximately similar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a simple dataset with ordered logit dgp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset(n_agents, params):\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "    range_vars = np.random.choice(range(2,4),size=len(beta))\n",
    "    X = np.concatenate(\n",
    "        [np.random.choice(range(x),size=n_agents).reshape(n_agents,1) for x in range_vars],axis=1)\n",
    "\n",
    "    # calculate deterministic part of utilities\n",
    "    xb = X.dot(beta).reshape(n_agents,1)\n",
    "\n",
    "    # Simulate Result:\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "\n",
    "    prob_cumulative = (upper_cdf - lower_cdf).cumsum(axis=1)\n",
    "    draws = np.random.rand(len(xb), 1)\n",
    "    labels = (draws < prob_cumulative).argmax(axis=1)\n",
    "    out = pd.DataFrame(X)\n",
    "    out.columns = params.loc[\"beta\"].index.values\n",
    "    out[\"y\"] = labels\n",
    "    return out\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_data_df(x,y,cols):\n",
    "    # Basic utility\n",
    "    data = np.concatenate([x,y.reshape(len(y),1)],axis=1)\n",
    "    return pd.DataFrame(data=data.copy(),columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing similar to the Likelihood example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_processing(formula, data):\n",
    "    \"\"\"Process user input for an ordered logit model.\"\"\"\n",
    "    # extract data arrays\n",
    "    y, x = dmatrices(formula + \" - 1\", data, return_type=\"dataframe\")\n",
    "    y = y[y.columns[0]]\n",
    "\n",
    "    # extract dimensions\n",
    "    num_choices = len(y.unique())\n",
    "    beta_names = list(x.columns)\n",
    "    num_betas = len(beta_names)\n",
    "    num_cutoffs = num_choices - 1\n",
    "\n",
    "    # set-up index for params_df\n",
    "    names = beta_names + list(range(num_cutoffs))\n",
    "    categories = [\"beta\"] * num_betas + [\"cutoff\"] * num_cutoffs\n",
    "    index = pd.MultiIndex.from_tuples(zip(categories, names), names=[\"type\", \"name\"])\n",
    "\n",
    "    # make params_df\n",
    "    np.random.seed(5471)\n",
    "    start_params = pd.DataFrame(index=index)\n",
    "    start_params[\"value\"] = np.hstack(\n",
    "        [\n",
    "            np.random.uniform(low=-0.5, high=0.5, size=len(x.columns)),\n",
    "            np.arange(num_cutoffs) * 2,\n",
    "        ]\n",
    "    )\n",
    "    start_params[\"group\"] = start_params.index.get_level_values(\"type\")\n",
    "\n",
    "    # make constraints\n",
    "    constr = [{\"loc\": \"cutoff\", \"type\": \"increasing\"}]\n",
    "\n",
    "    # turn pandas objects into numpy arrays\n",
    "    y_arr = y.to_numpy().astype(int)\n",
    "    x_arr = x.to_numpy()\n",
    "    \n",
    "    return start_params, y_arr, x_arr, constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_moments(data, ind):\n",
    "    \"\"\"\n",
    "    Map data into population moments.\n",
    "    data: pd.DataFrame that contains independent and dependent\n",
    "    variables for each individual\n",
    "    ind: list of independent variables that are used for conditional moments\n",
    "    \"\"\"\n",
    "    im = data.copy()\n",
    "    #im[\"gpa\"] = pd.qcut(im.gpa,q=3,labels=False)\n",
    "    ranges = data.max(axis=0)\n",
    "    ix = pd.MultiIndex.from_tuples(itertools.product(*(range(int(x + 1)) for x in ranges)))\n",
    "    ix.names = ind + [\"y\"]\n",
    "    out = pd.Series(index=ix,data=0)\n",
    "    rslt =  im.groupby(ind)[\"y\"].value_counts(normalize=True)\n",
    "    out[rslt.index] = rslt.values\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighting_matrix(\n",
    "    data,\n",
    "    empirical_moments,\n",
    "    calc_moments,\n",
    "    n_bootstrap_samples,\n",
    "    n_draws_individuals,\n",
    "    replace_missing_weights=None,\n",
    "    return_covariance_matrix=False,\n",
    "):\n",
    "    \"\"\"Compute a diagonal weighting matrix for estimation with MSM.\n",
    "    Weights are the inverse bootstrap variances of the observed sample moments.\n",
    "    Args:\n",
    "    ------\n",
    "    data (pandas.DataFrame)\n",
    "        Dataframe containing individual observations. Must contain index named\n",
    "        \"Identifier\" by which observations are sampled.\n",
    "    empirical_moments (dict)\n",
    "        Dictionary containing empirical moments in the form of pandas.DataFrame\n",
    "        or pandas.Series.\n",
    "    calc_moments (dict)\n",
    "        Dictionary containing moment functions.\n",
    "    n_bootstrap_samples (int)\n",
    "        Number of samples that should be boostrapped.\n",
    "    n_draws_individuals (int)\n",
    "        Observations per bootstrap sample (individual ids).\n",
    "    replace_missing_weights (None or float)\n",
    "        Can be used to replace missing weights with a float value. If none, in\n",
    "        cases where where weights are computed to be missing/infinite (i.e. if\n",
    "        variances are 0), weights are set to zero.\n",
    "    return_covariance_matrix : bool, default False\n",
    "        Return full covariance matrix of bootstrapped moments.\n",
    "    Returns:\n",
    "    --------\n",
    "    weighting_matrix (numpy.array)\n",
    "        Diagonal weighting matrix with dimensions RxR where R denotes the\n",
    "        number of moments.\n",
    "    covariance_matrix (numpy.array)\n",
    "        Covariance matrix of moments.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    np.random.seed(123)\n",
    "    flat_empirical_moments = get_flat_moments(empirical_moments)\n",
    "    index_base = data.index.get_level_values(0).unique()\n",
    "    calc_moments = _harmonize_input(calc_moments)\n",
    "    # Create bootstrapped moments.\n",
    "    moments_sample = []\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        ids_boot = np.random.choice(index_base, n_draws_individuals, replace=False)\n",
    "        moments_boot = {k: func(data.loc[ids_boot]) for k, func in calc_moments.items()}\n",
    "        flat_moments_boot = get_flat_moments(moments_boot)\n",
    "        flat_moments_boot = flat_moments_boot.reindex_like(flat_empirical_moments)\n",
    "        # flat_moments_boot = flat_moments_boot.fillna(0)\n",
    "        moments_sample.append(flat_moments_boot)\n",
    "\n",
    "    # Compute variance for each moment and construct diagonal weighting matrix.\n",
    "    moments_var = np.array(moments_sample).var(axis=0)\n",
    "\n",
    "    # The variance of missing moments is nan. Unless a replacement variance is\n",
    "    # specified, their inverse variance will be set to 0.\n",
    "    diagonal = moments_var ** (-1)\n",
    "    if replace_missing_weights is None:\n",
    "        diagonal = np.nan_to_num(diagonal, nan=0, posinf=0, neginf=0)\n",
    "    else:\n",
    "        diagonal = np.nan_to_num(\n",
    "            moments_var,\n",
    "            nan=replace_missing_weights,\n",
    "            posinf=replace_missing_weights,\n",
    "            neginf=replace_missing_weights,\n",
    "        )\n",
    "\n",
    "    weighting_matrix = np.diag(diagonal)\n",
    "\n",
    "    # Checks weighting matrix.\n",
    "    if np.isnan(weighting_matrix).any() or np.isinf(weighting_matrix).any():\n",
    "        raise ValueError(\"Weighting matrix contains NaNs or infinite values.\")\n",
    "\n",
    "    if return_covariance_matrix:\n",
    "        covariance_matrix = np.cov(np.array(moments_sample).T, ddof=0)\n",
    "        out = weighting_matrix, covariance_matrix\n",
    "        assert np.allclose(\n",
    "            moments_var, np.diag(covariance_matrix)\n",
    "        ), \"Variances in two outputs are not equal.\"\n",
    "    else:\n",
    "        out = weighting_matrix\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_msm(\n",
    "    params,\n",
    "    x,\n",
    "    moment_func,\n",
    "    moments_obs,\n",
    "    cols,\n",
    "    weighting=[],\n",
    "    return_scalar=True\n",
    "    \n",
    "):\n",
    "    \"\"\"MSM criterion for ordered logit\n",
    "    Maps params, independent data and moment obs in\n",
    "    model fit.\n",
    "    params: pd.DataFrame that contains parameters\n",
    "    x: np.array containing independent variables for individuals\n",
    "    moment_func: callable mapping data into moments\n",
    "    moments_obs: observed moments\n",
    "    cols: list of columns of data \n",
    "    \n",
    "    \"\"\"\n",
    "    # parse the parameter vector into its quantities\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "\n",
    "    # calculate deterministic part of utilities\n",
    "    xb = x.dot(beta).reshape(len(x),1)\n",
    "\n",
    "    # Simulate Result:\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "\n",
    "    prob_cumulative = (upper_cdf - lower_cdf).cumsum(axis=1)\n",
    "    draws = np.random.uniform(0,1,len(xb)).reshape(len(xb),1)\n",
    "    labels = (draws < prob_cumulative).argmax(axis=1)\n",
    "    \n",
    "    moments_sim = moment_func(_build_data_df(x,labels,cols))\n",
    "    \n",
    "    dev = (moments_sim - moments_obs).values\n",
    "    \n",
    "    if len(weighting)==0:\n",
    "        weighting = np.identity(len(moments_obs))\n",
    "    \n",
    "    if return_scalar:\n",
    "        return dev @ weighting @ dev\n",
    "    else:\n",
    "        return dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_loglike(\n",
    "    params,\n",
    "    y,\n",
    "    x\n",
    "):\n",
    "    \"\"\"Likelihood function of an orderd logit model.\n",
    "    taken from documentation \n",
    "    \"\"\"\n",
    "    # parse the parameter vector into its quantities\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "\n",
    "    # calculate deterministic part of utilities\n",
    "    xb = x.dot(beta)\n",
    "\n",
    "    # evaluate likelihood\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])[y]\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])[y]\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "\n",
    "    contributions = np.log(upper_cdf - lower_cdf)\n",
    "\n",
    "    res = {\"contributions\": contributions, \"value\": contributions.sum()}\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.DataFrame(pd.Series({\n",
    "    (\"beta\",\"a\"):-2,\n",
    "    (\"beta\",\"b\"):1,\n",
    "    (\"beta\",\"c\"):3,\n",
    "    (\"cutoff\",0):2,\n",
    "    (\"cutoff\",1):4,\n",
    "}))\n",
    "params.columns = [\"value\"]\n",
    "params[\"lower_bound\"] = - np.inf\n",
    "params[\"upper_bound\"] = np.inf\n",
    "\n",
    "params.index = pd.MultiIndex.from_tuples(params.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">beta</th>\n",
       "      <th>a</th>\n",
       "      <td>-2</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cutoff</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          value  lower_bound  upper_bound\n",
       "beta   a     -2         -inf          inf\n",
       "       b      1         -inf          inf\n",
       "       c      3         -inf          inf\n",
       "cutoff 0      2         -inf          inf\n",
       "       1      4         -inf          inf"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = simulate_dataset(50000, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind = [\"a\",\"b\",\"c\"] \n",
    "#im = data.copy()\n",
    "#ranges = data.max(axis=0)\n",
    "#ix = pd.MultiIndex.from_tuples(itertools.product(*(range(int(x + 1)) for x in ranges)))\n",
    "#ix.names = ind + [\"y\"]\n",
    "#out = pd.DataFrame(index=ix,data=0, columns=im.index)\n",
    "#rslt =  im.groupby(ind)[\"y\"]\n",
    "#for i in out.columns:\n",
    "    \n",
    "#    out.loc[tuple(im.loc[i]),i] = 1\n",
    "# Get Variance matrix here\n",
    "#Salt = np.cov(np.array(out))\n",
    "#W = np.diag(Salt)**(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set\n",
    "#data = pd.read_pickle(\"~/OpenSourceEconomics/estimagic/docs/source/getting_started/ologit.pickle\")\n",
    "formula = \"y ~ a + b + c\"\n",
    "start_params, y, x, constraints = ordered_logit_processing(formula, data)\n",
    "n = x.shape[0]\n",
    "n_agents_sim = 50000\n",
    "cols = [\"a\",\"b\",\"c\",\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = list(start_params.loc[\"beta\"].index.values)\n",
    "moments_obs = _build_moments(data,ind)\n",
    "moment_func = functools.partial(_build_moments,ind=ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we are not allowed to keep the dependent information due to privacy concerns.\n",
    "We are only allowed to extract a moments at a certain level of granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mo2561057/anaconda3/envs/ov_analysis/lib/python3.7/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in reciprocal\n"
     ]
    }
   ],
   "source": [
    "weighting, S = get_weighting_matrix(\n",
    "    data,\n",
    "    moments_obs,\n",
    "    moment_func,\n",
    "    n_bootstrap_samples=1000,\n",
    "    n_draws_individuals=100,\n",
    "    replace_missing_weights=None,\n",
    "    return_covariance_matrix=True,\n",
    ")\n",
    "S = S*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we pretend to leave our secure work space. Thus we have to delete y.\n",
    "#del y\n",
    "#del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the objective function\n",
    "objective = functools.partial(\n",
    "    ordered_logit_msm,\n",
    "    x=x,\n",
    "    moment_func=moment_func,\n",
    "    moments_obs=moments_obs,\n",
    "    weighting=weighting,\n",
    "    cols=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4493.295891312718"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We perform one evaluation to make sure our setup works\n",
    "objective(start_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optmize\n",
    "rslt = minimize(\n",
    "    criterion=objective,\n",
    "    params=start_params,\n",
    "    algorithm=\"scipy_powell\",\n",
    "    constraints=constraints,\n",
    "    logging=\"ordered_logit.db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_msm = rslt[\"solution_params\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">beta</th>\n",
       "      <th>a</th>\n",
       "      <td>beta</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>-1.963315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>beta</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.946459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>beta</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.885220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cutoff</th>\n",
       "      <th>0</th>\n",
       "      <td>cutoff</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.989266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cutoff</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>3.857928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              group  lower_bound  upper_bound     value\n",
       "type   name                                            \n",
       "beta   a       beta         -inf          inf -1.963315\n",
       "       b       beta         -inf          inf  0.946459\n",
       "       c       beta         -inf          inf  2.885220\n",
       "cutoff 0     cutoff         -inf          inf  1.989266\n",
       "       1     cutoff         -inf          inf  3.857928"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_msm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sandwich_cov(G, W, S, n):\n",
    "    bread = np.linalg.inv(\n",
    "        G.T @ W @ G\n",
    "    )\n",
    "    butter = G.T @ W @ S @ W @ G\n",
    "    return bread @ butter @ bread / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msm_standart_errors(objective, theta_hat, S, weighting, n):\n",
    "    # Get Hessian Matrix\n",
    "    G = first_derivative(\n",
    "    objective, \n",
    "    theta_hat, \n",
    "    method=\"central\", \n",
    "    #key=\"moment_errors\", \n",
    "    base_steps=0.3,\n",
    "    return_func_value=True,\n",
    "    n_cores=1,\n",
    "    )[0].to_numpy()\n",
    "    \n",
    "    \n",
    "    return sandwich_cov(G, W, S, n), G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = functools.partial(\n",
    "    ordered_logit_msm,\n",
    "    x=x,\n",
    "    moment_func=moment_func,\n",
    "    moments_obs=moments_obs,\n",
    "    weighting=weighting,\n",
    "    return_scalar=False,\n",
    "    cols=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">beta</th>\n",
       "      <th>a</th>\n",
       "      <td>-2</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cutoff</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          value  lower_bound  upper_bound\n",
       "beta   a     -2         -inf          inf\n",
       "       b      1         -inf          inf\n",
       "       c      3         -inf          inf\n",
       "cutoff 0      2         -inf          inf\n",
       "       1      4         -inf          inf"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b1f3fc3dcfb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_msm_standart_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-75cc04b0adf0>\u001b[0m in \u001b[0;36mget_msm_standart_errors\u001b[0;34m(objective, theta_hat, S, weighting, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msandwich_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "cov, G = get_msm_standart_errors(objective, params_msm, S, weighting, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.diag(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to likelihood errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set\n",
    "formula = \"y ~ a + b + c\"\n",
    "start_params, y, x, constraints = ordered_logit_processing(formula, data)\n",
    "n = x.shape[0]\n",
    "n_agents_sim = 50000\n",
    "cols = [\"a\",\"b\",\"c\",\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = maximize(\n",
    "    criterion=ordered_logit_loglike,\n",
    "    params=start_params,\n",
    "    algorithm=\"scipy_powell\",\n",
    "    constraints=constraints,\n",
    "    criterion_kwargs={\"y\": y, \"x\": x},\n",
    "    logging=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lk = res[\"solution_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_msm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se for likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimagic.decorators import numpy_interface\n",
    "\n",
    "numpy_interface(ordered_logit_loglike, params=params_lk, constraints=constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference, free_cov = do_likelihood_inference(\n",
    "    loglike=ordered_logit_loglike,\n",
    "    params=params_lk,\n",
    "    loglike_kwargs={\"x\": x, \"y\": y},\n",
    "    n_samples=50000,\n",
    "    constraints=constraints,\n",
    ")\n",
    "\n",
    "inference.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
